# app.py (versi贸n mejorada)

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
import plotly.express as px

# --- Configuraci贸n de la p谩gina ---
st.set_page_config(
    page_title="Comparaci贸n de Clasificadores ML",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- T铆tulo y descripci贸n ---
st.title(" Comparaci贸n de Modelos de Clasificaci贸n Interactiva")
st.markdown("Esta aplicaci贸n simula un conjunto de datos y eval煤a el rendimiento de tres algoritmos de clasificaci贸n.")
st.markdown("---")

# --- Barra Lateral para Par谩metros ---
st.sidebar.header("锔 Par谩metros del Dataset y Modelos")

# Sliders y selectbox para controlar los datos y modelos
n_samples = st.sidebar.slider("N煤mero de Muestras", min_value=100, max_value=1000, value=300, step=50)
n_features = st.sidebar.slider("N煤mero de Caracter铆sticas", min_value=3, max_value=10, value=6, step=1)
n_neighbors = st.sidebar.slider("Vecinos para KNN", min_value=1, max_value=20, value=5, step=1)
st.sidebar.markdown("---")


# --- Creaci贸n de los datos simulados ---
# Generamos los datos bas谩ndonos en los par谩metros de la barra lateral.
X, y = make_classification(
    n_samples=n_samples,
    n_features=n_features,
    n_informative=int(n_features * 0.7), # Un 70% de las caracter铆sticas son informativas
    n_redundant=int(n_features * 0.2), # Un 20% son redundantes
    n_classes=2,
    random_state=42
)
data = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(n_features)])
data['target'] = y

st.header("1. Conjunto de Datos Simulados")
st.info(f"Se ha creado un conjunto de datos con **{n_samples} muestras** y **{n_features} columnas**.")

# Secci贸n de EDA en un expander para mantener la UI limpia
with st.expander(" An谩lisis Exploratorio de Datos (EDA)", expanded=False):
    st.subheader("Visualizaci贸n del Dataset")
    st.dataframe(data.head())

    st.subheader("Distribuci贸n de la Variable Objetivo")
    # Gr谩fico de barras para la distribuci贸n de 'target'
    target_counts = data['target'].value_counts().reset_index()
    target_counts.columns = ['Clase', 'Conteo']
    st.bar_chart(target_counts.set_index('Clase'))

    st.subheader("Gr谩fico de Dispersi贸n de Caracter铆sticas")
    # Gr谩fico interactivo para ver la relaci贸n entre dos caracter铆sticas
    features_list = data.columns[:-1].tolist()
    col1, col2 = st.columns(2)
    with col1:
        feature_x = st.selectbox("Eje X", options=features_list)
    with col2:
        feature_y = st.selectbox("Eje Y", options=features_list, index=1 if len(features_list) > 1 else 0)

    fig = px.scatter(data, x=feature_x, y=feature_y, color='target',
                     title=f'Dispersi贸n de {feature_x} vs {feature_y}')
    st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

# --- Divisi贸n y Entrenamiento ---
st.header("2. Entrenamiento y Evaluaci贸n de Modelos")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

st.info(f"El conjunto de datos se ha dividido en entrenamiento ({len(X_train)}) y prueba ({len(X_test)}).")

# Definici贸n de modelos con par谩metros personalizables
knn = KNeighborsClassifier(n_neighbors=n_neighbors)
decision_tree = DecisionTreeClassifier(random_state=42)
naive_bayes = GaussianNB()

models = {
    'KNN': knn,
    'rbol de Decisi贸n': decision_tree,
    'Clasificador Bayesiano': naive_bayes
}

# Bucle para entrenar y evaluar
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy

# --- Mostrar Resultados ---
st.header("3. Resultados de Precisi贸n (Accuracy)")
st.write("A continuaci贸n, se muestra la precisi贸n de cada modelo en el conjunto de prueba:")

results_df = pd.DataFrame(results.items(), columns=['Modelo', 'Precisi贸n'])
# Formateamos la precisi贸n a porcentaje
results_df['Precisi贸n'] = results_df['Precisi贸n'].apply(lambda x: f"{x:.2%}")
st.table(results_df.style.highlight_max(axis=0))
st.success("隆El modelo con mayor precisi贸n ha sido resaltado!")
st.markdown("---")

# --- Conclusi贸n ---
st.header("Conclusi贸n")
st.write("Ahora puedes experimentar con los par谩metros en la barra lateral para ver c贸mo cambian los resultados. 隆Observa c贸mo la precisi贸n de los modelos se ve afectada al modificar el tama帽o del dataset o el n煤mero de vecinos en KNN!")
